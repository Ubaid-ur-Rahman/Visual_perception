{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b5bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import skimage.feature as feature\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71890899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(h, std_dev):\n",
    "    # It calculates and Returns a normalized Gaussian kernel with dimension (h x h)\n",
    "    kernel = np.zeros((h, h))\n",
    "    center = h // 2\n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(h):\n",
    "            x, y = i - center, j - center\n",
    "            kernel[i][j] = np.exp(-(x**2 + y**2) / (2 * std_dev**2))\n",
    "    return kernel / np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df3d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_image(img):\n",
    "    #It calculates the gradient images of x and y using the Sobel filter and Gaussian smoothing.   \n",
    "    # Defining the Sobel filters\n",
    "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    \n",
    "    # Applying Gaussian smoothing with sigma = 0.2\n",
    "    gaussian_kernel_3x3 = gaussian_kernel(5, 0.2)\n",
    "    img_smoothed = ndimage.convolve(img, gaussian_kernel_3x3, mode='reflect')\n",
    "    \n",
    "    # Calculating the gradient images through Sobel filters\n",
    "    Ix = ndimage.convolve(img_smoothed, sobel_x, mode='reflect')\n",
    "    Iy = ndimage.convolve(img_smoothed, sobel_y, mode='reflect')\n",
    "    \n",
    "    return Ix, Iy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0116fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_response(Ix, Iy, w, alpha=0.01):\n",
    "    #It calculates the Harris corner response R for all pixels in the image.\n",
    "    # Calculating the IxIx, IyIy and IxIy matrices\n",
    "    IxIx = ndimage.convolve(Ix**2, w, mode='reflect')\n",
    "    IyIy = ndimage.convolve(Iy**2, w, mode='reflect')\n",
    "    IxIy = ndimage.convolve(Ix * Iy, w, mode='reflect')\n",
    "    \n",
    "    # Calculating the Harris response R\n",
    "    det = IxIx * IyIy - IxIy**2\n",
    "    trace = IxIx + IyIy\n",
    "    R = det - alpha * trace**2\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc279ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_non_maxsup(R, img_shape):\n",
    "    corners = feature.peak.peak_local_max(R, min_distance=7, threshold_rel=0.01)\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c033cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, keypoints, N=32):\n",
    "    #First we create border, then create blob of N pixels, according to assignment, N should be 32.\n",
    "    patches = []\n",
    "    img = cv2.copyMakeBorder(img, top=N//2, bottom=N//2, left=N//2, right=N//2, borderType=cv2.BORDER_REPLICATE)\n",
    "    for x, y in keypoints:\n",
    "        x += N//2\n",
    "        y += N//2\n",
    "        patch = img[y-N//2:y+N//2, x-N//2:x+N//2]\n",
    "        patches.append(patch)\n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82496149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_normalized_patches(patches):\n",
    "    # It calculates the normalized patches by applying the farmula available on the assignment document\n",
    "    normalized_patches = []\n",
    "    for patch in patches:\n",
    "        normalized_patch = (patch - np.mean(patch)) / (np.std(patch) + 1e-7)\n",
    "        normalized_patches.append(normalized_patch)\n",
    "    return normalized_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec059270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(normalized_patches1, normalized_patches2):\n",
    "    K1 = len(normalized_patches1)\n",
    "    K2 = len(normalized_patches2)\n",
    "    N = normalized_patches1[0].shape[0]   \n",
    "    distance_matrix = np.zeros((K1, K2))\n",
    "    for i in range(K1):\n",
    "        for j in range(K2):\n",
    "            patch1 = normalized_patches1[i]\n",
    "            patch2 = normalized_patches2[j]\n",
    "            if patch2.shape[0] == patch1.shape[0] and patch2.shape[1] == patch1.shape[1]  :\n",
    "                distance_matrix[i, j] = np.sum((patch1 - patch2)**2)\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e2011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(D):\n",
    "    #It calculates the matches \n",
    "    matches = []\n",
    "    for i in range(D.shape[1]):\n",
    "        index = np.argmin(D[:, i])\n",
    "        if index != i:\n",
    "            matches.append((index, i))\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b9d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches_robust(patches1, patches2):\n",
    "    #It calculates the matches by applying ratio test\n",
    "    D = distance_matrix(patches1, patches2)\n",
    "    matched_indexes = []\n",
    "    for i in range(D.shape[1]):\n",
    "        column = D[:,i]\n",
    "        nn1_index = np.argmin(column)\n",
    "        nn2_index = np.argsort(column)[1]\n",
    "        nn1_distance = column[nn1_index]\n",
    "        nn2_distance = column[nn2_index]\n",
    "        ratio = nn1_distance / nn2_distance\n",
    "        if ratio < 0.8:\n",
    "            matched_indexes.append((nn1_index, i))\n",
    "    filtered_matches = []\n",
    "    for index1, index2 in matched_indexes:\n",
    "        patch1 = patches1[index1]\n",
    "        patch2 = patches2[index2]\n",
    "        if np.linalg.norm(patch1 - patch2) < 0.1:\n",
    "            filtered_matches.append((index1, index2))\n",
    "    return filtered_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0465b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vs_detected_keypoints(matches):\n",
    "    #It calculates average number of detected and tracked keypoints\n",
    "    keypoints_per_frame = []\n",
    "    for i in range(199):\n",
    "        keypoints_per_frame.append(len(matches))\n",
    "    average_keypoints = sum(keypoints_per_frame) / len(keypoints_per_frame)\n",
    "    return average_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6be902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_descriptors(corners, image, patch_size=32):\n",
    "    img = cv2.merge([image, image, image]).astype(np.uint8)\n",
    "    sift_descriptors = []\n",
    "    sift = cv2.SIFT_create()\n",
    "    for corner in corners:\n",
    "        x, y = corner\n",
    "        patch = img[x-patch_size//2:x+patch_size//2, y-patch_size//2:y+patch_size//2]\n",
    "        #if image.depth() != cv2.CV_8U:\n",
    "        _,descriptors = sift.compute(patch, None)\n",
    "        sift_descriptors.append(descriptors)\n",
    "    return sift_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e277fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video ( list_image_names ) :\n",
    "    # reads the images\n",
    "    img_array = []\n",
    "    for filename in sorted ( list_image_names ):\n",
    "        img = cv2.imread ( filename )\n",
    "        img_array.append ( img )\n",
    "\n",
    "    # video size = image size\n",
    "    height , width , layers = img . shape\n",
    "    size = ( width , height )\n",
    "    # create mp4 writer with 3 FPS\n",
    "    video_wr = cv2.VideoWriter ('corner_tracking_patch .mp4', cv2.VideoWriter_fourcc (* 'mp4v') , 3 , size )\n",
    "    for i in range(len(img_array)):\n",
    "        video_wr.write(img_array [i])\n",
    "        video_wr.release ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59bc2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches(image_tgt, list_keypoints_src, list_keypoints_tgt, matches):\n",
    "    image_color = cv2.cvtColor(image_tgt, cv2.COLOR_GRAY2BGR)\n",
    "    # add cross for each keypoint in target image\n",
    "    for keyp in list_keypoints_tgt:\n",
    "        cv2.drawMarker(image_color, (keyp[1], keyp[0]), (0, 0, 255),\n",
    "        markerType = cv2.MARKER_CROSS, markerSize = 3, thickness = 3, \n",
    "        line_type = cv2.LINE_8)\n",
    "    # draw green lines of matches\n",
    "    for i, j in matches:\n",
    "        coord_src, coord_tgt = list_keypoints_src[i], list_keypoints_tgt[j]\n",
    "    # please note that coordinates are inverted to follow opencv convention (x, y) instead of (y, x)\n",
    "        cv2.line(image_color,(coord_tgt[1], coord_tgt[0]),(coord_src[1], coord_src[0]),(0, 255, 0),1)\n",
    "    # display image\n",
    "    cv2.imshow(\"Matches\", image_color)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb3d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corners(img, corners):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.plot(corners[:, 1], corners[:, 0], 'r+', markersize=10, markeredgewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27105e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on the frames\n",
    "for i in range (1,80):\n",
    "    star1= str(i-1).zfill(6)\n",
    "    path1 = \"images/\" + star1 + \".png\"\n",
    "    img1 = plt.imread(\"images/000000.png\")\n",
    "    #img = np.mean(img, axis=2)\n",
    "    Ix1, Iy1 = gradient_image(img1)\n",
    "    R1 = harris_response(Ix1, Iy1, gaussian_kernel(5, 1))\n",
    "    corners1 = response_non_maxsup(R1, img1.shape)\n",
    "    patches1= extract_patches(img1, corners1, 32)\n",
    "    normalized_patches1= extract_normalized_patches(patches1)\n",
    "\n",
    "    star2= str(i).zfill(6)\n",
    "    path2 = \"images/\" + star2 + \".png\"\n",
    "    img2 = plt.imread(\"images/000000.png\")\n",
    "    #img = np.mean(img, axis=2)\n",
    "    Ix2, Iy2 = gradient_image(img2)\n",
    "    R2 = harris_response(Ix2, Iy2, gaussian_kernel(5, 1))\n",
    "    corners2 = response_non_maxsup(R2, img2.shape)\n",
    "    patches2= extract_patches(img2, corners2, 32)\n",
    "    normalized_patches2= extract_normalized_patches(patches2)\n",
    "\n",
    "    #normalized_patches1 = extract_sift_descriptors(corners1,img1)\n",
    "    #normalized_patches2 = extract_sift_descriptors(corners2 , img2)\n",
    "\n",
    "    #for patch in normalized_patches2:\n",
    "    #    print(\"The patch is\", patch.shape[0]) \n",
    "\n",
    "    Distance=distance_matrix(normalized_patches2, normalized_patches1)\n",
    "    Matches= find_matches(Distance)\n",
    "    Robust_matches= find_matches_robust(normalized_patches1, normalized_patches2)\n",
    "    #Comparison = average_vs_detected_keypoints (Matches)\n",
    "    plot_matches (img2, corners1, corners2, Matches)\n",
    "    #plot_corners(img1, corners1)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba37d69516b96b2df66115ef342e83722e1a1518f5d2e0ee41eb08141fa2fe2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
