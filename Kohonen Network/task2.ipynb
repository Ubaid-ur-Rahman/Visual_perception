{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the implementation of training and testing the kohonen Network. The instructor has provided me with 3 files, the ‘healthy.mat’ file contains data from healthy subjects and the ‘patient.mat’ contains patient data. Each line corresponds to the data (time series) coming from one subject.  The time series is made up of the displacements of markers placed on the joints of subjects. There are ten subjects in each file. Of course, the same markers are used for all subjects. I do not have to adjust anything in each time series as the information from each marker has already been put in the correct position in the time series. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets import all the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from minisom import MiniSom\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I loaded all the .mat files and relevant data into the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = loadmat('healthy.mat')\n",
    "data2 = loadmat('patient.mat')\n",
    "testing = loadmat('ubaid.mat')\n",
    "\n",
    "#keys = testing_data.keys()\n",
    "#print(keys)\n",
    "\n",
    "healthy_data = data['x']\n",
    "patient_data = data2['x']\n",
    "testing_data = testing['z']\n",
    "\n",
    "print(testing_data)\n",
    "print(patient_data)\n",
    "print(healthy_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I concatenated both the patient_data as well as healthy_data into one single all_data. After that, I calculated the length of each time series in the all_data array by accessing the second dimension of the array's shape. Then I normalized the all_data and testing_data array by dividing each element by the Euclidean norm of the entire array.\n",
    "For defining the dimensions of kohonen network, I set the input_shape variable to the length of each time series, as calculated earlier. Then set the network_shape variable to a tuple representing the dimensions of the Kohonen network. Then I created an instance of the MiniSom class, representing the Kohonen network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.concatenate((healthy_data, patient_data), axis=0)\n",
    "\n",
    "# Get the length of each time series\n",
    "time_series_length = all_data.shape[1]\n",
    "\n",
    "# Normalize the data\n",
    "all_data = all_data / np.linalg.norm(all_data)\n",
    "normalized_testing = testing_data / np.linalg.norm(testing_data)\n",
    "\n",
    "# Define the dimensions of the Kohonen network\n",
    "input_shape = time_series_length\n",
    "network_shape = (8, 8)  # Adjust the network shape as needed\n",
    "\n",
    "# Create the Kohonen network\n",
    "network = MiniSom(network_shape[0], network_shape[1], input_shape, sigma=0.5, learning_rate=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After everything is set, the next step is training, First i initialized the weights randomly and make iterations 1000 (its variable), and then i train the all_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weights randomly\n",
    "network.random_weights_init(all_data)\n",
    "\n",
    "# Train the network\n",
    "num_iterations = 1000  # Adjust the number of iterations as needed\n",
    "network.train_batch(all_data, num_iterations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then comes the part of testing. I initialized an array of zeros with a length equal to the number of testing samples. Then a loop that iterates over the normalized testing samples.The sample is flattened to a 1D array using flatten() to match the input shape expected by the winner method of the Kohonen network. Then I calculated the index of the winning neuron in a flattened network representation. It multiplies the row index by the number of columns in the network (network_shape[1]) and adds the col index.\n",
    "Lastly, I assigned the calculated winner_index to the i-th element of the winners array, indicating the index of the winning neuron for the current testing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels for testing samples:\n",
      "['Healthy', 'Healthy', 'Healthy', 'Healthy']\n"
     ]
    }
   ],
   "source": [
    "winners = np.zeros(len(normalized_testing))\n",
    "for i, sample in enumerate(normalized_testing):\n",
    "    row, col = network.winner(sample.flatten())  # Get the row and column coordinates of the winner\n",
    "    winner_index = row * network_shape[1] + col  # Calculate the index of the winner in a flattened network\n",
    "    winners[i] = winner_index\n",
    "\n",
    "# Define the class labels for healthy and patient\n",
    "class_labels = ['Healthy', 'Patient']\n",
    "\n",
    "# Map the winners to the class labels\n",
    "predicted_labels = [class_labels[int(winner_index) % len(class_labels)] for winner_index in winners]\n",
    "\n",
    "print(\"Predicted labels for testing samples:\")\n",
    "print(predicted_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main differences between Kohonen network, K-means, and K-nearest neighbor (KNN) techniques:\n",
    "\n",
    "### Kohonen Network\n",
    "\n",
    "*   A type of self-organizing map (SOM) that uses unsupervised learning to produce a low-dimensional (typically 2D) representation of the input space.\n",
    "*   It clusters similar data points together in the same region of the map.\n",
    "*   It creates a topological structure that preserves the relationships between the input data points.\n",
    "*   It is useful for visualizing high-dimensional data and identifying patterns in the data.\n",
    "\n",
    "### K-means\n",
    "\n",
    "*   A clustering algorithm that partitions data into K distinct clusters based on their similarity.\n",
    "*   It requires the user to specify the number of clusters (K) in advance.\n",
    "*   It tries to minimize the sum of squared distances between points and their assigned cluster centers.\n",
    "*   It is computationally efficient and works well with large datasets.\n",
    "\n",
    "### K-nearest neighbor (KNN)\n",
    "\n",
    "*   A classification algorithm that classifies data points based on their proximity to other data points in the feature space.\n",
    "*   It requires the user to specify the number of nearest neighbors (K) to consider.\n",
    "*   It assigns the class label of the majority of the K nearest neighbors to the new data point.\n",
    "*   It is a lazy learning algorithm, meaning it does not have a training phase, and instead, relies on the entire training dataset during classification.\n",
    "\n",
    "In summary, the Kohonen network is a self-organizing map that creates a low-dimensional representation of the input space, while K-means is a clustering algorithm that partitions data into K distinct clusters based on similarity, and KNN is a classification algorithm that assigns the class label of the majority of the K nearest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
